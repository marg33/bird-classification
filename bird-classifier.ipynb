{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Bird classifier\n","\n","Trains a classifier to predict the species of birds from images.\n","\n","Based on [tutorial 3](https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing) and [tutorial 4](https://colab.research.google.com/drive/1kHo8VT-onDxbtS3FM77VImG35h_K_Lav?usp=sharing) from class."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-09T22:54:47.595138Z","iopub.status.busy":"2023-06-09T22:54:47.594855Z","iopub.status.idle":"2023-06-09T22:54:51.361094Z","shell.execute_reply":"2023-06-09T22:54:51.360147Z","shell.execute_reply.started":"2023-06-09T22:54:47.595113Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-09T22:54:51.363785Z","iopub.status.busy":"2023-06-09T22:54:51.362970Z","iopub.status.idle":"2023-06-09T22:54:51.369442Z","shell.execute_reply":"2023-06-09T22:54:51.368566Z","shell.execute_reply.started":"2023-06-09T22:54:51.363748Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# size to resize the train images to. I tried out 128, 256\n","image_size = 256\n","\n","# a string to append to the names of generated files, to track some of the transformations I used for image augmentation and changes in hyperparameters\n","transform = \"crop_hflip_lr_5_01_8_001_10_0001_12_41_m_09_5_05_10_01_12_0_0d\"\n","\n","# make checkpoints path\n","checkpoints = '/kaggle/working/checkpoints/size_' + str(image_size) + \"-\" + transform + \"-\"\n","if not os.path.exists(checkpoints):\n","    os.makedirs(checkpoints)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Getting and processing the data\n","\n","`get_bird_data` takes the train and test data of the bird datasets and processes them. This is where we resize the images and apply augmentations."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-09T22:58:05.419862Z","iopub.status.busy":"2023-06-09T22:58:05.419390Z","iopub.status.idle":"2023-06-09T22:58:07.678109Z","shell.execute_reply":"2023-06-09T22:58:07.677143Z","shell.execute_reply.started":"2023-06-09T22:58:05.419821Z"},"trusted":true},"outputs":[],"source":["def get_bird_data(augmentation=0):\n","    \n","    # comment out augmentations we don't want to currently use\n","    transform_train = transforms.Compose([\n","        # always performed\n","        transforms.Resize(image_size), \n","        transforms.RandomCrop(image_size, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n","        \n","        # tried adding different additional augmentations!\n","        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n","#         transforms.TrivialAugmentWide(),\n","#         transforms.RandAugment(),\n","#         transforms.AugMix();\n","        transforms.RandomVerticalFlip(),    # 50% of time flip image along x-axis\n","        transforms.RandomPerspective(distortion_scale=0.2, p=0.15),\n","#         transforms.RandomAffine(degrees=(0, 180), translate=(0.01, 0.3), scale=(0.5, 0.75)),\n","        transforms.RandomRotation(degrees=(0, 10)),\n","        transforms.RandomAutocontrast(),\n","        transforms.ColorJitter(brightness=.5, hue=.3, contrast=0, saturation=.05),\n","        transforms.ToTensor(),\n","    ])\n","    \n","    transform_test = transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.ToTensor(),\n","    ])\n","    trainset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/train', transform=transform_train)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","    testset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/test', transform=transform_test)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n","    classes = open(\"/kaggle/input/birds23sp/birds/names.txt\").read().strip().split(\"\\n\")\n","    class_to_idx = trainset.class_to_idx\n","    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n","    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n","    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n","\n","data = get_bird_data()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def accuracy(net, dataloader):\n","  net.to(device)\n","  net.eval()\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for batch in dataloader:\n","          images, labels = batch[0].to(device), batch[1].to(device)\n","          outputs = net(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","  return correct/total"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-09T22:58:07.761488Z","iopub.status.busy":"2023-06-09T22:58:07.760432Z","iopub.status.idle":"2023-06-09T22:58:12.406425Z","shell.execute_reply":"2023-06-09T22:58:12.404958Z","shell.execute_reply.started":"2023-06-09T22:58:07.761449Z"},"trusted":true},"outputs":[],"source":["# view some of our images after processing. Useful for seeing the effects of augmentations\n","\n","dataiter = iter(data['train'])\n","images, labels = next(dataiter)\n","images = images[:8]\n","print(images.size())\n","\n","def imshow(img):\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(\"Labels:\" + ', '.join('%9s' % data['to_name'][labels[j].item()] for j in range(8)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train function\n","def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n","          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n","    net.to(device)\n","    net.train()\n","    losses = []\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n","\n","    # Load previous training state\n","    if state:\n","        net.load_state_dict(state['net'])\n","        optimizer.load_state_dict(state['optimizer'])\n","        start_epoch = state['epoch']\n","        losses = state['losses']\n","\n","    # Fast forward lr schedule through already trained epochs\n","    for epoch in range(start_epoch):\n","        if epoch in schedule:\n","            print (\"Learning rate: %f\"% schedule[epoch])\n","            for g in optimizer.param_groups:\n","                g['lr'] = schedule[epoch]\n","\n","    for epoch in range(start_epoch, epochs):\n","        sum_loss = 0.0\n","\n","        # Update learning rate when scheduled\n","        if epoch in schedule:\n","            print (\"Learning rate: %f\"% schedule[epoch])\n","            for g in optimizer.param_groups:\n","                g['lr'] = schedule[epoch]\n","\n","        for i, batch in enumerate(dataloader, 0):\n","            inputs, labels = batch[0].to(device), batch[1].to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()  # autograd magic, computes all the partial derivatives\n","            optimizer.step() # takes a step in gradient direction\n","\n","            losses.append(loss.item())\n","            sum_loss += loss.item()\n","\n","            if i % print_every == print_every-1:    # print every 10 mini-batches\n","                if verbose:\n","                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n","                sum_loss = 0.0\n","        if checkpoint_path:\n","            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n","            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n","    return losses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def smooth(x, size):\n","  return np.convolve(x, np.ones(size)/size, mode='valid')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# prediction function\n","def predict(net, dataloader, ofname):\n","    out = open(ofname, 'w')\n","    out.write(\"path,class\\n\")\n","    net.to(device)\n","    net.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for i, (images, labels) in enumerate(dataloader, 0):\n","            if i%100 == 0:\n","                print(i)\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            fname, _ = dataloader.dataset.samples[i]\n","            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n","    out.close()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","Use ResNet-18 for pretraining and finetune on the bird train data. We can add more epochs and adjust hyperparameters here."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n","resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n","\n","# comment out training functions we don't want to use currently\n","\n","# losses = train(resnet, data['train'], epochs=5, lr=.01, print_every=10, checkpoint_path=checkpoints)\n","losses = train(resnet, data['train'], decay=0, epochs=5, lr=.01, print_every=10, checkpoint_path=checkpoints)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n","resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n","state = torch.load(checkpoints + 'checkpoint-5.pkl')\n","# losses = train(resnet, data['train'], epochs=12, decay=0, schedule={0:.01, 8:.001, 10:0.0001}, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)\n","# losses = train(resnet, data['train'], epochs=10, momentum=0.5, schedule={0:.01, 8:.001}, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)\n","losses = train(resnet, data['train'], epochs=10, decay=0, momentum=0.5, schedule={0:.01, 8:.001}, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)\n","\n","# losses = train(resnet, data['train'], epochs=7, schedule={0:.01, 4:.001}, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)\n","# losses = train(resnet, data['train'], epochs=20, schedule={0:.01, 8:.001}, lr=.01, print_every=10, checkpoint_path=checkpoints, state=state)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-08T23:47:13.918951Z","iopub.status.busy":"2023-06-08T23:47:13.918574Z","iopub.status.idle":"2023-06-08T23:47:13.946549Z","shell.execute_reply":"2023-06-08T23:47:13.945014Z","shell.execute_reply.started":"2023-06-08T23:47:13.918924Z"},"trusted":true},"outputs":[],"source":["resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n","resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n","state = torch.load(checkpoints + 'checkpoint-10.pkl')\n","# losses = train(resnet, data['train'], epochs=12, momentum=0.1, lr=.0001, print_every=10, checkpoint_path=checkpoints, state=state)\n","# losses = train(resnet, data['train'], epochs=12, decay=0, momentum=0.1, lr=.0001, print_every=10, checkpoint_path=checkpoints, state=state)\n","losses = train(resnet, data['train'], epochs=12, decay=0, momentum=0.1, lr=.0001, print_every=10, checkpoint_path=checkpoints, state=state)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n","resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n","state = torch.load(checkpoints + 'checkpoint-12.pkl') # change number for how many epochs we used\n","losses = train(resnet, data['train'], epochs=16, decay=0, momentum=0, lr=.00001, print_every=10, checkpoint_path=checkpoints, state=state)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save a plot of the losses\n","plt.plot(smooth(losses,50))\n","plt.title(label=\"Losses for size \" + str(image_size) + transform)\n","plt.savefig(checkpoints + 'train_losses.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save a plot of the losses\n","state = torch.load(checkpoints + 'checkpoint-16.pkl') # change num for epochs used\n","plt.plot(smooth(state['losses'], 50))\n","plt.title(label=\"State losses for \" + str(image_size) + transform)\n","plt.savefig(checkpoints + 'train_state.png')\n","\n","# Load model from checkpoint\n","resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n","resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n","state = torch.load(checkpoints + 'checkpoint-16.pkl') # change num for epochs used\n","resnet.load_state_dict(state['net'])\n","\n","# make predictions\n","predict(resnet, data['test'], checkpoints + \"preds_augmented.csv\")\n","\n","print(\"Training  accuracy: %f\" % accuracy(resnet, data['train']))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
